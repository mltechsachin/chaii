{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "median-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is written to solve the hindi and Tamil Question - Answer task and will use seperate models to run for each Hindi and Tamil. I am using seq-to-seq  with attension model\n",
    "# to output the answer for the input question in those two given languages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.hi import Hindi \n",
    "from spacy.lang.ta import Tamil\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test = True  \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c805a4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encoder LSTM \n",
    "class EncoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "    super(EncoderLSTM, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "    self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "  def forward(self, inputs, hidden):\n",
    "    # Embed input words\n",
    "    embedded = self.embedding(inputs)\n",
    "    # Pass the embedded word vectors into LSTM and return all outputs\n",
    "    output, hidden = self.lstm(embedded, hidden)\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size=1):\n",
    "    return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "251eb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauDecoder(nn.Module):\n",
    "  def __init__(self, hidden_size, output_size, n_layers=1, drop_prob=0.1):\n",
    "    super(BahdanauDecoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.drop_prob = drop_prob\n",
    "\n",
    "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "    \n",
    "    self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "    self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "    self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "    self.dropout = nn.Dropout(self.drop_prob)\n",
    "    self.lstm = nn.LSTM(self.hidden_size*2, self.hidden_size, batch_first=True)\n",
    "    self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "  def forward(self, inputs, hidden, encoder_outputs):\n",
    "    encoder_outputs = encoder_outputs.squeeze()\n",
    "    # Embed input words\n",
    "    embedded = self.embedding(inputs).view(1, -1)\n",
    "    embedded = self.dropout(embedded)\n",
    "\n",
    "    # Calculating Alignment Scores\n",
    "    x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "    alignment_scores = x.bmm(self.weight.unsqueeze(2))  \n",
    "    \n",
    "    # Softmaxing alignment scores to get Attention weights\n",
    "    attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
    "    \n",
    "    # Multiplying the Attention weights with encoder outputs to get the context vector\n",
    "    context_vector = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                             encoder_outputs.unsqueeze(0))\n",
    "    \n",
    "    # Concatenating context vector with embedded input word\n",
    "    output = torch.cat((embedded, context_vector[0]), 1).unsqueeze(0)\n",
    "    # Passing the concatenated vector as input to the LSTM cell\n",
    "    output, hidden = self.lstm(output, hidden)\n",
    "    # Passing the LSTM output through a Linear layer acting as a classifier\n",
    "    output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "    #print(output)\n",
    "    #        import sys; sys.exit()\n",
    "    return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d874610f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-327c122c6a3c>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(training_examples_hi)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffc1571ec744aa090d42192452b1ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-327c122c6a3c>:48: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(training_examples_ta)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be98e0572bfd436aae3505beed9540e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-327c122c6a3c>:89: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(test_examples_hi)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac2d356921e4b62b74e077c8c8b7511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-327c122c6a3c>:93: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(test_examples_ta)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e5b1db428a4429b092bd24a589c6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "questions = data['question']\n",
    "answers = data['answer_text']\n",
    "#Setting the number of training sentences we'll use\n",
    "#training_examples = len(questions)\n",
    "training_examples_hi = len(questions.loc[data['language']=='hindi'])\n",
    "training_examples_ta = len(questions.loc[data['language']=='tamil'])\n",
    "\n",
    "spacy_hi = Hindi()\n",
    "spacy_ta = Tamil()\n",
    "words_hi = Counter()\n",
    "words_ta = Counter()\n",
    "\n",
    "\n",
    "qu_inputs = []\n",
    "an_inputs = []\n",
    "for i in tqdm_notebook(range(training_examples_hi)):\n",
    "    qu_tokens_hi = spacy_hi(questions.loc[data['language']=='hindi'].iloc[i])\n",
    "    an_tokens_hi = spacy_hi(answers.loc[data['language']=='hindi'].iloc[i])\n",
    "    if len(qu_tokens_hi)==0 or len(an_tokens_hi)==0:\n",
    "        continue\n",
    "    for qu_token in qu_tokens_hi:\n",
    "        words_hi.update([qu_token.text])\n",
    "    for an_token in an_tokens_hi:\n",
    "        words_hi.update([an_token.text])\n",
    "    qu_inputs.append([token.text for token in qu_tokens_hi] + ['_EOS'])\n",
    "    an_inputs.append([token.text for token in an_tokens_hi] + ['_EOS'])\n",
    "\n",
    "#Writing this part for hindi and tamil questions and answers of train set\n",
    "words_hi_vocab = ['_SOS','_EOS','_UNK'] + sorted(words_hi,key=words_hi.get,reverse=True)\n",
    "hi_w2i = {o:i for i,o in enumerate(words_hi_vocab)}\n",
    "hi_i2w = {i:o for i,o in enumerate(words_hi_vocab)}\n",
    "\n",
    "#Converting only Hindi sentences to their token indexes\n",
    "qu_inputs_hi = []\n",
    "an_inputs_hi = []\n",
    "#print(words_hi_vocab)\n",
    "for i in range(len(qu_inputs)):\n",
    "    qu_sentence = qu_inputs[i]\n",
    "    an_sentence = an_inputs[i]\n",
    "    qu_inputs_hi.append([hi_w2i[word] for word in qu_sentence])\n",
    "    an_inputs_hi.append([hi_w2i[word] for word in an_sentence])\n",
    "                        \n",
    "                        \n",
    "qu_inputs = []\n",
    "an_inputs = []\n",
    "#Similarly tokenizing tamil quentions and answers\n",
    "for i in tqdm_notebook(range(training_examples_ta)):\n",
    "    qu_tokens_ta = spacy_ta(questions.loc[data['language']=='tamil'].iloc[i])\n",
    "    an_tokens_ta = spacy_ta(answers.loc[data['language']=='tamil'].iloc[i])\n",
    "    if len(qu_tokens_ta)==0 or len(an_tokens_ta)==0:\n",
    "        continue\n",
    "    for qu_token in qu_tokens_ta:\n",
    "        words_ta.update([qu_token.text])\n",
    "    for an_token in an_tokens_ta:\n",
    "        words_ta.update([an_token.text])\n",
    "    qu_inputs.append([token.text for token in qu_tokens_ta] + ['_EOS'])\n",
    "    an_inputs.append([token.text for token in an_tokens_ta] + ['_EOS'])\n",
    "    \n",
    "    \n",
    "words_ta_vocab = ['_SOS','_EOS','_UNK'] + sorted(words_ta,key=words_ta.get,reverse=True)\n",
    "ta_w2i = {o:i for i,o in enumerate(words_ta_vocab)}\n",
    "ta_i2w = {i:o for i,o in enumerate(words_ta_vocab)}\n",
    "  \n",
    "#Converting only Tamil sentences to their token indexes\n",
    "qu_inputs_ta = []\n",
    "an_inputs_ta = []\n",
    "#print(words_hi_vocab)\n",
    "for i in range(len(qu_inputs)):\n",
    "    qu_sentence = qu_inputs[i]\n",
    "    an_sentence = an_inputs[i]\n",
    "    qu_inputs_ta.append([ta_w2i[word] for word in qu_sentence])\n",
    "    an_inputs_ta.append([ta_w2i[word] for word in an_sentence])\n",
    "    \n",
    "\n",
    "\n",
    "#for test set\n",
    "#qu_inputs\n",
    "if test == True:\n",
    "    qu_inputs_test_hi = []\n",
    "    qu_inputs_test_ta = []\n",
    "    data_test = pd.read_csv('test.csv')\n",
    "    questions_test = data_test['question']\n",
    "    #for test examples\n",
    "    test_examples_hi = len(questions_test.loc[data_test['language']=='hindi'])\n",
    "    test_examples_ta = len(questions_test.loc[data_test['language']=='tamil'])\n",
    "    qu_inputs_hi_temp = []\n",
    "    qu_inputs_ta_temp = []\n",
    "    for i in tqdm_notebook(range(test_examples_hi)):\n",
    "        qu_tokens_hi_test = spacy_hi(questions_test.loc[data_test['language']=='hindi'].iloc[i])\n",
    "        qu_inputs_hi_temp.append([token.text for token in qu_tokens_hi_test] + ['_EOS'])\n",
    "    #Similarly tokenizing tamil quentions\n",
    "    for i in tqdm_notebook(range(test_examples_ta)):\n",
    "        qu_tokens_ta_test = spacy_hi(questions_test.loc[data_test['language']=='tamil'].iloc[i])\n",
    "        qu_inputs_ta_temp.append([token.text for token in qu_tokens_ta_test] + ['_EOS'])\n",
    "    #writing indexes for Hindi and tamil test questions\n",
    "    for i in range(len(qu_inputs_hi_temp)):\n",
    "        qu_sentence = qu_inputs_hi_temp[i]\n",
    "        qu_inputs_test_hi.append([hi_w2i[word] if words_hi[word] else hi_w2i['_UNK'] for word in qu_sentence])\n",
    "    for i in range(len(qu_inputs_ta_temp)):\n",
    "        qu_sentence = qu_inputs_ta_temp[i]\n",
    "        qu_inputs_test_ta.append([ta_w2i[word] if words_ta[word] else ta_w2i['_UNK'] for word in qu_sentence])\n",
    "    #For submission of test results on Kaggle\n",
    "    sub = pd.read_csv('sample_submission.csv')\n",
    "    pred_id_hi = data_test['id'].loc[data_test['language'] == 'hindi'].reset_index()\n",
    "    pred_id_ta = data_test['id'].loc[data_test['language'] == 'tamil'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fc31ba1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-c9728a052c09>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204435e77a934a17b8b0d691c0634f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-c9728a052c09>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk1 = tqdm_notebook(enumerate(qu_inputs_hi[0:len(qu_inputs_hi)-1]),total=len(qu_inputs_hi)-1,leave=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Writing for hindi training model and then testing\n",
    "hidden_size = 256\n",
    "encoder = EncoderLSTM(len(words_hi), hidden_size).to(device)\n",
    "#attn = Attention(hidden_size,\"concat\")\n",
    "#decoder = LuongDecoder(hidden_size,len(words_hi),attn).to(device)\n",
    "decoder = BahdanauDecoder(hidden_size,len(words_hi)).to(device)\n",
    "lr = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "EPOCHS = 10\n",
    "teacher_forcing_prob = 0.5\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n",
    "for epoch in tk0:\n",
    "    avg_loss = 0.\n",
    "    tk1 = tqdm_notebook(enumerate(qu_inputs_hi[0:len(qu_inputs_hi)-1]),total=len(qu_inputs_hi)-1,leave=False)\n",
    "    for i, sentence in tk1:\n",
    "        loss = 0.\n",
    "        h = encoder.init_hidden()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        #print(sentence)\n",
    "        inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "        #print(encoder_outputs)\n",
    "        #First decoder input will be the SOS token\n",
    "        decoder_input = torch.tensor([hi_w2i['_SOS']],device=device)\n",
    "        #First decoder hidden state will be last encoder hidden state\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        for ii in range(len(an_inputs_hi[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #Get the index value of the word with the highest score from the decoder output\n",
    "            #print(decoder_output)\n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([an_inputs_hi[i][ii]],device=device)\n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            output.append(top_index.item())\n",
    "            #Calculate the loss of ?the prediction against the actual word\n",
    "            loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([an_inputs_hi[i][ii]],device=device))\n",
    "            #print(loss)\n",
    "            #import sys; sys.exit()\n",
    "        loss = loss/len(an_inputs_hi[i])\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        avg_loss += loss.item()/len(qu_inputs_hi)\n",
    "    tk0.set_postfix(loss=avg_loss)\n",
    "    #Save model after every epoch (Optional)\n",
    "    torch.save({\"encoder\":encoder.state_dict(),\"decoder\":decoder.state_dict(),\"e_optimizer\":encoder_optimizer.state_dict(),\"d_optimizer\":decoder_optimizer},\"./model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71d722a3-79db-41f2-9d7c-e319364e1150",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: _UNK _UNK की माँ का नाम क्या है _UNK\n",
      "Answer Predicted: \"\n",
      "Hindi: _UNK _UNK कब लॉन्च किया गया था ? _UNK\n",
      "Answer Predicted: 15 दिसम्बर\n",
      "Hindi: गुस्ताव _UNK का जन्म कब हुआ था ? _UNK\n",
      "Answer Predicted: 15 अप्रैल 1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-2635531f4115>:35: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['']+[hi_i2w[x] for x in qu_inputs_test_hi[i]])\n",
      "<ipython-input-78-2635531f4115>:36: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['']+[hi_i2w[x] for x in output])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-2635531f4115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhi_i2w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqu_inputs_test_hi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhi_i2w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2327 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2369 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2360 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2381 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2357 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2325 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2332 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2344 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2350 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2348 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2361 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2310 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2341 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2309 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2346 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2352 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2376 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 2354 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2327 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2369 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2360 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2381 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2357 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2325 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2332 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2344 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2350 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2348 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2361 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2310 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2341 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2309 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2346 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2352 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2376 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 2354 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if test == True:\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    #\n",
    "    #i = random.randint(0,len(qu_inputs_test_hi)-1)\n",
    "    #Doing for all hindi sentences\n",
    "    for i in range(len(qu_inputs_test_hi)):\n",
    "        h = encoder.init_hidden()\n",
    "        inp = torch.tensor(qu_inputs_test_hi[i]).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "\n",
    "        decoder_input = torch.tensor([hi_w2i['_SOS']],device=device)\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        attentions = []\n",
    "        while True:\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _, top_index = decoder_output.topk(1)\n",
    "            decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            #If the decoder output is the End Of Sentence token, stop decoding process\n",
    "            if top_index.item() == hi_w2i[\"_EOS\"]:\n",
    "                break\n",
    "            output.append(top_index.item())\n",
    "            attentions.append(attn_weights.squeeze().cpu().detach().numpy())\n",
    "        in_string = \" \".join([hi_i2w[x] for x in qu_inputs_test_hi[i]])\n",
    "        out_string = \" \".join([hi_i2w[x] for x in output])\n",
    "        print(\"Hindi: \"+ in_string)\n",
    "        print(\"Answer Predicted: \" + out_string)\n",
    "        sub['PredictionString'].loc[sub['id'] == pred_id_hi['id'][i]] = out_string\n",
    "    #Plotting the heatmap for the Attention weights\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(np.array(attentions))\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels(['']+[hi_i2w[x] for x in qu_inputs_test_hi[i]])\n",
    "    ax.set_yticklabels(['']+[hi_i2w[x] for x in output])\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac63a53-e43c-4fd9-8975-5b25988c70a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b3cb5e4635e4>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cc6e42b96b4709906d0482cb542eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b3cb5e4635e4>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk1 = tqdm_notebook(enumerate(qu_inputs_ta[0:len(qu_inputs_ta)-2]),total=len(qu_inputs_ta)-2,leave=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Writing for tamil training model  and testing\n",
    "hidden_size = 256\n",
    "encoder = EncoderLSTM(len(words_ta), hidden_size).to(device)\n",
    "#attn = Attention(hidden_size,\"concat\")\n",
    "#decoder = LuongDecoder(hidden_size,len(words_hi),attn).to(device)\n",
    "decoder = BahdanauDecoder(hidden_size,len(words_ta)).to(device)\n",
    "lr = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "EPOCHS = 10\n",
    "teacher_forcing_prob = 0.5\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n",
    "for epoch in tk0:\n",
    "    avg_loss = 0.\n",
    "    tk1 = tqdm_notebook(enumerate(qu_inputs_ta[0:len(qu_inputs_ta)-2]),total=len(qu_inputs_ta)-2,leave=False)\n",
    "    for i, sentence in tk1:\n",
    "        loss = 0.\n",
    "        h = encoder.init_hidden()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        #print(sentence)\n",
    "        inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "        #print(encoder_outputs)\n",
    "        #First decoder input will be the SOS token\n",
    "        decoder_input = torch.tensor([ta_w2i['_SOS']],device=device)\n",
    "        #First decoder hidden state will be last encoder hidden state\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        for ii in range(len(an_inputs_ta[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #Get the index value of the word with the highest score from the decoder output\n",
    "            #print(decoder_output)\n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([an_inputs_ta[i][ii]],device=device)\n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            output.append(top_index.item())\n",
    "            #Calculate the loss of ?the prediction against the actual word\n",
    "            loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([an_inputs_ta[i][ii]],device=device))\n",
    "            #print(loss)\n",
    "            #import sys; sys.exit()\n",
    "        loss = loss/len(an_inputs_ta[i])\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        avg_loss += loss.item()/len(qu_inputs_ta)\n",
    "    tk0.set_postfix(loss=avg_loss)\n",
    "    #Save model after every epoch (Optional)\n",
    "    torch.save({\"encoder\":encoder.state_dict(),\"decoder\":decoder.state_dict(),\"e_optimizer\":encoder_optimizer.state_dict(),\"d_optimizer\":decoder_optimizer},\"./model_ta.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a52b1382-0f49-43f0-9886-d8fdfee1346e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamil: _UNK அணு எண் என்ன ? _UNK\n",
      "Answer Predicted: மண்டேலா உலகில் ரகுமான் சார்லஸ்\n",
      "Tamil: இந்தியாவில் _UNK _UNK தந்தை என்று கருதப்படுபவர் யார் ? _UNK\n",
      "Answer Predicted: மண்டேலா உலகில் ரகுமான்\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-ef5a0434807f>:35: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['']+[ta_i2w[x] for x in qu_inputs_test_ta[i]])\n",
      "<ipython-input-76-ef5a0434807f>:36: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['']+[ta_i2w[x] for x in output])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-ef5a0434807f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mta_i2w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqu_inputs_test_ta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mta_i2w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if test == True:   \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    #Choose a random sentences\n",
    "    #i = random.randint(0,len(qu_inputs_test_ta)-1)\n",
    "    #Doing decoding for all tamil sentences\n",
    "    for i in range(len(qu_inputs_test_ta)):\n",
    "        h = encoder.init_hidden()\n",
    "        inp = torch.tensor(qu_inputs_test_ta[i]).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "\n",
    "        decoder_input = torch.tensor([ta_w2i['_SOS']],device=device)\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        attentions = []\n",
    "        while True:\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _, top_index = decoder_output.topk(1)\n",
    "            decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            #If the decoder output is the End Of Sentence token, stop decoding process\n",
    "            if top_index.item() == ta_w2i[\"_EOS\"]:\n",
    "                break\n",
    "            output.append(top_index.item())\n",
    "            attentions.append(attn_weights.squeeze().cpu().detach().numpy())\n",
    "        in_string = \" \".join([ta_i2w[x] for x in qu_inputs_test_ta[i]])\n",
    "        out_string = \" \".join([ta_i2w[x] for x in output])\n",
    "        print(\"Tamil: \"+ in_string)\n",
    "        print(\"Answer Predicted: \" + out_string)\n",
    "        sub['PredictionString'].loc[sub['id'] == pred_id_ta['id'][i]] = out_string\n",
    "    #Plotting the heatmap for the Attention weights\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(np.array(attentions))\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels(['']+[ta_i2w[x] for x in qu_inputs_test_ta[i]])\n",
    "    ax.set_yticklabels(['']+[ta_i2w[x] for x in output])\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cc6a3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Saving to sample submission csv file\n",
    "sub.to_csv('sample_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

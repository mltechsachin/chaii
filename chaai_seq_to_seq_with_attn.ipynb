{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is written to solve the hindi and Tamil Question - Answer task and will use seperate models to run for each Hindi and Tamil. I am using seq-to-seq  with attension model\n",
    "# to output the answer for the input question in those two given languages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.hi import Hindi \n",
    "from spacy.lang.ta import Tamil\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import random\n",
    "\n",
    "test = True  \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c805a4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encoder LSTM \n",
    "class EncoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "    super(EncoderLSTM, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "    self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "  def forward(self, inputs, hidden):\n",
    "    # Embed input words\n",
    "    embedded = self.embedding(inputs)\n",
    "    # Pass the embedded word vectors into LSTM and return all outputs\n",
    "    output, hidden = self.lstm(embedded, hidden)\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size=1):\n",
    "    return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251eb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauDecoder(nn.Module):\n",
    "  def __init__(self, hidden_size, output_size, n_layers=1, drop_prob=0.1):\n",
    "    super(BahdanauDecoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.drop_prob = drop_prob\n",
    "\n",
    "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "    \n",
    "    self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "    self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "    self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "    self.dropout = nn.Dropout(self.drop_prob)\n",
    "    self.lstm = nn.LSTM(self.hidden_size*2, self.hidden_size, batch_first=True)\n",
    "    self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "  def forward(self, inputs, hidden, encoder_outputs):\n",
    "    encoder_outputs = encoder_outputs.squeeze()\n",
    "    # Embed input words\n",
    "    embedded = self.embedding(inputs).view(1, -1)\n",
    "    embedded = self.dropout(embedded)\n",
    "\n",
    "    # Calculating Alignment Scores\n",
    "    x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "    alignment_scores = x.bmm(self.weight.unsqueeze(2))  \n",
    "    \n",
    "    # Softmaxing alignment scores to get Attention weights\n",
    "    attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
    "    \n",
    "    # Multiplying the Attention weights with encoder outputs to get the context vector\n",
    "    context_vector = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                             encoder_outputs.unsqueeze(0))\n",
    "    \n",
    "    # Concatenating context vector with embedded input word\n",
    "    output = torch.cat((embedded, context_vector[0]), 1).unsqueeze(0)\n",
    "    # Passing the concatenated vector as input to the LSTM cell\n",
    "    output, hidden = self.lstm(output, hidden)\n",
    "    # Passing the LSTM output through a Linear layer acting as a classifier\n",
    "    output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "    #print(output)\n",
    "    #        import sys; sys.exit()\n",
    "    return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d874610f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-87487c7fc5f2>:67: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(training_examples_hi)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600590d276ca4686b3cc56e929a8ef2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-87487c7fc5f2>:98: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(training_examples_ta)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4304451d5b8942aab4e803acb3f22dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-87487c7fc5f2>:139: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(test_examples_hi)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027e3a3dc8314bc6bc89c6d50805c412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-87487c7fc5f2>:143: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(test_examples_ta)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f53eeb6aa44c8f82527e82953d987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "questions = data['question']\n",
    "answers = data['answer_text']\n",
    "#Setting the number of training sentences we'll use\n",
    "#training_examples = len(questions)\n",
    "training_examples_hi = len(questions.loc[data['language']=='hindi'])\n",
    "training_examples_ta = len(questions.loc[data['language']=='tamil'])\n",
    "\n",
    "spacy_hi = Hindi()\n",
    "spacy_ta = Tamil()\n",
    "words_hi = Counter()\n",
    "words_ta = Counter()\n",
    "\n",
    "\n",
    "qu_inputs = []\n",
    "an_inputs = []\n",
    "for i in tqdm_notebook(range(training_examples_hi)):\n",
    "    qu_tokens_hi = spacy_hi(questions.loc[data['language']=='hindi'].iloc[i])\n",
    "    an_tokens_hi = spacy_hi(answers.loc[data['language']=='hindi'].iloc[i])\n",
    "    if len(qu_tokens_hi)==0 or len(an_tokens_hi)==0:\n",
    "        continue\n",
    "    for qu_token in qu_tokens_hi:\n",
    "        words_hi.update([qu_token.text])\n",
    "    for an_token in an_tokens_hi:\n",
    "        words_hi.update([an_token.text])\n",
    "    qu_inputs.append([token.text for token in qu_tokens_hi] + ['_EOS'])\n",
    "    an_inputs.append([token.text for token in an_tokens_hi] + ['_EOS'])\n",
    "\n",
    "#Writing this part for hindi and tamil questions and answers of train set\n",
    "words_hi_vocab = ['_SOS','_EOS','_UNK'] + sorted(words_hi,key=words_hi.get,reverse=True)\n",
    "hi_w2i = {o:i for i,o in enumerate(words_hi_vocab)}\n",
    "hi_i2w = {i:o for i,o in enumerate(words_hi_vocab)}\n",
    "\n",
    "#Converting only Hindi sentences to their token indexes\n",
    "qu_inputs_hi = []\n",
    "an_inputs_hi = []\n",
    "#print(words_hi_vocab)\n",
    "for i in range(len(qu_inputs)):\n",
    "    qu_sentence = qu_inputs[i]\n",
    "    an_sentence = an_inputs[i]\n",
    "    qu_inputs_hi.append([hi_w2i[word] for word in qu_sentence])\n",
    "    an_inputs_hi.append([hi_w2i[word] for word in an_sentence])\n",
    "                        \n",
    "                        \n",
    "qu_inputs = []\n",
    "an_inputs = []\n",
    "#Similarly tokenizing tamil quentions and answers\n",
    "for i in tqdm_notebook(range(training_examples_ta)):\n",
    "    qu_tokens_ta = spacy_ta(questions.loc[data['language']=='tamil'].iloc[i])\n",
    "    an_tokens_ta = spacy_ta(answers.loc[data['language']=='tamil'].iloc[i])\n",
    "    if len(qu_tokens_ta)==0 or len(an_tokens_ta)==0:\n",
    "        continue\n",
    "    for qu_token in qu_tokens_ta:\n",
    "        words_ta.update([qu_token.text])\n",
    "    for an_token in an_tokens_ta:\n",
    "        words_ta.update([an_token.text])\n",
    "    qu_inputs.append([token.text for token in qu_tokens_ta] + ['_EOS'])\n",
    "    an_inputs.append([token.text for token in an_tokens_ta] + ['_EOS'])\n",
    "    \n",
    "    \n",
    "words_ta_vocab = ['_SOS','_EOS','_UNK'] + sorted(words_ta,key=words_ta.get,reverse=True)\n",
    "ta_w2i = {o:i for i,o in enumerate(words_ta_vocab)}\n",
    "ta_i2w = {i:o for i,o in enumerate(words_ta_vocab)}\n",
    "  \n",
    "#Converting only Tamil sentences to their token indexes\n",
    "qu_inputs_ta = []\n",
    "an_inputs_ta = []\n",
    "#print(words_hi_vocab)\n",
    "for i in range(len(qu_inputs)):\n",
    "    qu_sentence = qu_inputs[i]\n",
    "    an_sentence = an_inputs[i]\n",
    "    qu_inputs_ta.append([ta_w2i[word] for word in qu_sentence])\n",
    "    an_inputs_ta.append([ta_w2i[word] for word in an_sentence])\n",
    "    \n",
    "\n",
    "\n",
    "#for test set\n",
    "#qu_inputs\n",
    "if test == True:\n",
    "    qu_inputs_test_hi = []\n",
    "    qu_inputs_test_ta = []\n",
    "    data_test = pd.read_csv('test.csv')\n",
    "    questions_test = data_test['question']\n",
    "    #for test examples\n",
    "    test_examples_hi = len(questions_test.loc[data_test['language']=='hindi'])\n",
    "    test_examples_ta = len(questions_test.loc[data_test['language']=='tamil'])\n",
    "    qu_inputs_hi_temp = []\n",
    "    qu_inputs_ta_temp = []\n",
    "    for i in tqdm_notebook(range(test_examples_hi)):\n",
    "        qu_tokens_hi_test = spacy_hi(questions_test.loc[data_test['language']=='hindi'].iloc[i])\n",
    "        qu_inputs_hi_temp.append([token.text for token in qu_tokens_hi_test] + ['_EOS'])\n",
    "    #Similarly tokenizing tamil quentions\n",
    "    for i in tqdm_notebook(range(test_examples_ta)):\n",
    "        qu_tokens_ta_test = spacy_hi(questions_test.loc[data_test['language']=='tamil'].iloc[i])\n",
    "        qu_inputs_ta_temp.append([token.text for token in qu_tokens_ta_test] + ['_EOS']) \n",
    "    #writing indexes for Hindi and tamil test questions\n",
    "    for i in range(len(qu_inputs_hi_temp)):\n",
    "        qu_sentence = qu_inputs_hi_temp[i]\n",
    "        qu_inputs_test_hi.append([hi_w2i[word] if words_hi[word] else hi_w2i['_UNK'] for word in qu_sentence])\n",
    "    for i in range(len(qu_inputs_ta_temp)):\n",
    "        qu_sentence = qu_inputs_ta_temp[i]\n",
    "        qu_inputs_test_ta.append([ta_w2i[word] if words_ta[word] else ta_w2i['_UNK'] for word in qu_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0fc31ba1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-288-c9728a052c09>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543d60da0ad64d3990342de4d165a008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-288-c9728a052c09>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk1 = tqdm_notebook(enumerate(qu_inputs_hi[0:len(qu_inputs_hi)-1]),total=len(qu_inputs_hi)-1,leave=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b73a2d7b1f4ed2b5952a365628781c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-c9728a052c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#import sys; sys.exit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0man_inputs_hi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Writing for hindi training model and then testing\n",
    "hidden_size = 256\n",
    "encoder = EncoderLSTM(len(words_hi), hidden_size).to(device)\n",
    "#attn = Attention(hidden_size,\"concat\")\n",
    "#decoder = LuongDecoder(hidden_size,len(words_hi),attn).to(device)\n",
    "decoder = BahdanauDecoder(hidden_size,len(words_hi)).to(device)\n",
    "lr = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "EPOCHS = 10\n",
    "teacher_forcing_prob = 0.5\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n",
    "for epoch in tk0:\n",
    "    avg_loss = 0.\n",
    "    tk1 = tqdm_notebook(enumerate(qu_inputs_hi[0:len(qu_inputs_hi)-1]),total=len(qu_inputs_hi)-1,leave=False)\n",
    "    for i, sentence in tk1:\n",
    "        loss = 0.\n",
    "        h = encoder.init_hidden()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        #print(sentence)\n",
    "        inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "        #print(encoder_outputs)\n",
    "        #First decoder input will be the SOS token\n",
    "        decoder_input = torch.tensor([hi_w2i['_SOS']],device=device)\n",
    "        #First decoder hidden state will be last encoder hidden state\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        for ii in range(len(an_inputs_hi[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #Get the index value of the word with the highest score from the decoder output\n",
    "            #print(decoder_output)\n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([an_inputs_hi[i][ii]],device=device)\n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            output.append(top_index.item())\n",
    "            #Calculate the loss of ?the prediction against the actual word\n",
    "            loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([an_inputs_hi[i][ii]],device=device))\n",
    "            #print(loss)\n",
    "            #import sys; sys.exit()\n",
    "        loss = loss/len(an_inputs_hi[i])\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        avg_loss += loss.item()/len(qu_inputs_hi)\n",
    "    tk0.set_postfix(loss=avg_loss)\n",
    "    #Save model after every epoch (Optional)\n",
    "    torch.save({\"encoder\":encoder.state_dict(),\"decoder\":decoder.state_dict(),\"e_optimizer\":encoder_optimizer.state_dict(),\"d_optimizer\":decoder_optimizer},\"./model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d722a3-79db-41f2-9d7c-e319364e1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "#Choose a random sentences\n",
    "i = random.randint(0,len(qu_inputs_test_hi)-1)\n",
    "h = encoder.init_hidden()\n",
    "inp = torch.tensor(qu_inputs_test_hi[i]).unsqueeze(0).to(device)\n",
    "encoder_outputs, h = encoder(inp,h)\n",
    "\n",
    "decoder_input = torch.tensor([hi_w2i['_SOS']],device=device)\n",
    "decoder_hidden = h\n",
    "output = []\n",
    "attentions = []\n",
    "while True:\n",
    "    decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    _, top_index = decoder_output.topk(1)\n",
    "    decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "    #If the decoder output is the End Of Sentence token, stop decoding process\n",
    "    if top_index.item() == hi_w2i[\"_EOS\"]:\n",
    "        break\n",
    "    output.append(top_index.item())\n",
    "    attentions.append(attn_weights.squeeze().cpu().detach().numpy())\n",
    "print(\"Hindi: \"+ \" \".join([hi_i2w[x] for x in qu_inputs_test_hi[i]]))\n",
    "print(\"Answer Predicted: \" + \" \".join([hi_i2w[x] for x in output]))\n",
    "\n",
    "#Plotting the heatmap for the Attention weights\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(np.array(attentions))\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels(['']+[hi_i2w[x] for x in qu_inputs_test_hi[i]])\n",
    "ax.set_yticklabels(['']+[hi_i2w[x] for x in output])\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac63a53-e43c-4fd9-8975-5b25988c70a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b3cb5e4635e4>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cc6e42b96b4709906d0482cb542eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b3cb5e4635e4>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk1 = tqdm_notebook(enumerate(qu_inputs_ta[0:len(qu_inputs_ta)-2]),total=len(qu_inputs_ta)-2,leave=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Writing for tamil training model  and testing\n",
    "hidden_size = 256\n",
    "encoder = EncoderLSTM(len(words_ta), hidden_size).to(device)\n",
    "#attn = Attention(hidden_size,\"concat\")\n",
    "#decoder = LuongDecoder(hidden_size,len(words_hi),attn).to(device)\n",
    "decoder = BahdanauDecoder(hidden_size,len(words_ta)).to(device)\n",
    "lr = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "EPOCHS = 10\n",
    "teacher_forcing_prob = 0.5\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "tk0 = tqdm_notebook(range(1,EPOCHS+1),total=EPOCHS)\n",
    "for epoch in tk0:\n",
    "    avg_loss = 0.\n",
    "    tk1 = tqdm_notebook(enumerate(qu_inputs_ta[0:len(qu_inputs_ta)-2]),total=len(qu_inputs_ta)-2,leave=False)\n",
    "    for i, sentence in tk1:\n",
    "        loss = 0.\n",
    "        h = encoder.init_hidden()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        #print(sentence)\n",
    "        inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "        #print(encoder_outputs)\n",
    "        #First decoder input will be the SOS token\n",
    "        decoder_input = torch.tensor([ta_w2i['_SOS']],device=device)\n",
    "        #First decoder hidden state will be last encoder hidden state\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        for ii in range(len(an_inputs_ta[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #Get the index value of the word with the highest score from the decoder output\n",
    "            #print(decoder_output)\n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([an_inputs_ta[i][ii]],device=device)\n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            output.append(top_index.item())\n",
    "            #Calculate the loss of ?the prediction against the actual word\n",
    "            loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([an_inputs_ta[i][ii]],device=device))\n",
    "            #print(loss)\n",
    "            #import sys; sys.exit()\n",
    "        loss = loss/len(an_inputs_ta[i])\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        avg_loss += loss.item()/len(qu_inputs_ta)\n",
    "    tk0.set_postfix(loss=avg_loss)\n",
    "    #Save model after every epoch (Optional)\n",
    "    torch.save({\"encoder\":encoder.state_dict(),\"decoder\":decoder.state_dict(),\"e_optimizer\":encoder_optimizer.state_dict(),\"d_optimizer\":decoder_optimizer},\"./model_ta.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52b1382-0f49-43f0-9886-d8fdfee1346e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi: இந்தியாவில் _UNK _UNK தந்தை என்று கருதப்படுபவர் யார் ? _UNK\n",
      "Answer Predicted: ஆடம்\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dcb5f3ef6cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Plotting the heatmap for the Attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "#Choose a random sentences\n",
    "i = random.randint(0,len(qu_inputs_test_ta)-1)\n",
    "h = encoder.init_hidden()\n",
    "inp = torch.tensor(qu_inputs_test_ta[i]).unsqueeze(0).to(device)\n",
    "encoder_outputs, h = encoder(inp,h)\n",
    "\n",
    "decoder_input = torch.tensor([ta_w2i['_SOS']],device=device)\n",
    "decoder_hidden = h\n",
    "output = []\n",
    "attentions = []\n",
    "while True:\n",
    "    decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    _, top_index = decoder_output.topk(1)\n",
    "    decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "    #If the decoder output is the End Of Sentence token, stop decoding process\n",
    "    if top_index.item() == ta_w2i[\"_EOS\"]:\n",
    "        break\n",
    "    output.append(top_index.item())\n",
    "    attentions.append(attn_weights.squeeze().cpu().detach().numpy())\n",
    "print(\"Hindi: \"+ \" \".join([ta_i2w[x] for x in qu_inputs_test_ta[i]]))\n",
    "print(\"Answer Predicted: \" + \" \".join([ta_i2w[x] for x in output]))\n",
    "\n",
    "#Plotting the heatmap for the Attention weights\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(np.array(attentions))\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels(['']+[ta_i2w[x] for x in qu_inputs_test_ta[i]])\n",
    "ax.set_yticklabels(['']+[ta_i2w[x] for x in output])\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6a3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
